{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "import sqlalchemy as sqa\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func,inspect\n",
    "\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import glob \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the next few kernels we will connect to PostGRES and create a new DB\n",
    "# Connect to PostgreSQL DBMS\n",
    "database = 'nba2018db'\n",
    "user = 'postgres'\n",
    "password ='password' #needs password\n",
    "\n",
    "con = psycopg2.connect(\"user=postgres password='lachimie'\");\n",
    "con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a DB Cursor\n",
    "cursor = con.cursor();\n",
    "name_Database = \"nba2018db\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table statement\n",
    "sqlCreateDatabase = \"create database \"+name_Database+\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table in PostgreSQL database and then close the connection\n",
    "cursor.execute(sqlCreateDatabase);\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the new database\n",
    "# a second cursor was created so that it would connect properly to the new db\n",
    "\n",
    "con = psycopg2.connect(database='nba2018db', user=user, password=password)\n",
    "cursor2 = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('code','sql','NBA2018.sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the export of the ERD diagram from https://app.quickdatabasediagrams.com/#/\n",
    "#to create the tables in the nba2018db\n",
    "\n",
    "sql_file = open(filepath,'r', encoding='utf-8-sig')\n",
    "cursor2.execute(sql_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['players', 'teams', 'players_team', 'salary', 'combine', 'games', 'stats']\n"
     ]
    }
   ],
   "source": [
    "#create an iterable list of our inputs from the directory\n",
    "\n",
    "directory_path = 'outputs/*.csv'\n",
    "file_list = []\n",
    "\n",
    "for fname in glob.glob(directory_path):\n",
    "    file_list.append(fname)\n",
    "\n",
    "file_list\n",
    "table_list = []\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    table_list.append(file_list[i].replace('outputs\\\\', '').replace('_cleaned.csv',''))\n",
    "\n",
    "for i in range(len(table_list)):\n",
    "    table_list[i] = table_list[i][2:]\n",
    "    \n",
    "print(table_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open(file_list[0], 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     next(reader) # Skip the header row.\n",
    "#     for row in reader:\n",
    "#         cursor2.execute(\n",
    "#         f\"INSERT INTO {table_list[0]} VALUES ({row})\",\n",
    "#         row\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ingest all of the CSV file into the database using an for-loop\n",
    "#a null='NULL' statement is required so that any empty field \n",
    "#is ingested properly\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "#     filepath = os.path.join('outputs','teams_cleaned.csv')\n",
    "    with open(file_list[i], 'r') as f:\n",
    "        next(f) # Skip the header row.\n",
    "        cursor2.copy_from(f, table_list[i], sep=',', null='NULL')\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cursor2.close()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
